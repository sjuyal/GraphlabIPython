{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using deep features to build an image classifier\n",
    "\n",
    "#Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load a common image analysis dataset\n",
    "\n",
    "We will use a popular benchmark dataset in computer vision called CIFAR-10.  \n",
    "\n",
    "(We've reduced the data to just 4 categories = {'cat','bird','automobile','dog'}.)\n",
    "\n",
    "This dataset is already split into a training set and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1530271318.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to sjuyal.23@gmail.com and will expire on June 24, 2019.\n"
     ]
    }
   ],
   "source": [
    "image_train = graphlab.SFrame('image_train_data/')\n",
    "image_test = graphlab.SFrame('image_test_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphlab.canvas.set_target('browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is accessible via web browser at the URL: http://localhost:52638/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "image_train['image'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">deep_features</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_array</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.242871761322,<br>1.09545373917, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[73.0, 77.0, 58.0, 71.0,<br>68.0, 50.0, 77.0, 69.0, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[1 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tint\n",
       "\timage\tImage\n",
       "\tlabel\tstr\n",
       "\tdeep_features\tarray\n",
       "\timage_array\tarray\n",
       "\n",
       "Rows: 1\n",
       "\n",
       "Data:\n",
       "+----+----------------------+-------+-------------------------------+\n",
       "| id |        image         | label |         deep_features         |\n",
       "+----+----------------------+-------+-------------------------------+\n",
       "| 24 | Height: 32 Width: 32 |  bird | [0.242871761322, 1.0954537... |\n",
       "+----+----------------------+-------+-------------------------------+\n",
       "+-------------------------------+\n",
       "|          image_array          |\n",
       "+-------------------------------+\n",
       "| [73.0, 77.0, 58.0, 71.0, 6... |\n",
       "+-------------------------------+\n",
       "[1 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train a classifier on the raw image pixels\n",
    "\n",
    "We first start by training a classifier on just the raw pixels of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 1900\n",
      "PROGRESS: Number of classes           : 4\n",
      "PROGRESS: Number of feature columns   : 1\n",
      "PROGRESS: Number of unpacked features : 3072\n",
      "PROGRESS: Number of coefficients    : 9219\n",
      "PROGRESS: Starting L-BFGS\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 6        | 0.000013  | 1.298911     | 0.280526          | 0.276190            |\n",
      "PROGRESS: | 2         | 8        | 1.000000  | 1.426180     | 0.364211          | 0.314286            |\n",
      "PROGRESS: | 3         | 9        | 1.000000  | 1.499995     | 0.411579          | 0.409524            |\n",
      "PROGRESS: | 4         | 10       | 1.000000  | 1.577665     | 0.435263          | 0.514286            |\n",
      "PROGRESS: | 5         | 11       | 1.000000  | 1.653563     | 0.464211          | 0.533333            |\n",
      "PROGRESS: | 6         | 12       | 1.000000  | 1.727710     | 0.467368          | 0.523810            |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "raw_pixel_model = graphlab.logistic_classifier.create(image_train,target='label',\n",
    "                                              features=['image_array'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make a prediction with the simple model based on raw pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "image_test[0:3]['image'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['cat', 'automobile', 'cat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test[0:3]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['bird', 'cat', 'bird']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pixel_model.predict(image_test[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model makes wrong predictions for all three images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluating raw pixel model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.48025, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 16\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      2       |        0        |  148  |\n",
       " |      3       |        3        |  408  |\n",
       " |      1       |        2        |  168  |\n",
       " |      1       |        1        |  536  |\n",
       " |      2       |        3        |  276  |\n",
       " |      0       |        3        |  107  |\n",
       " |      2       |        1        |  217  |\n",
       " |      0       |        2        |  157  |\n",
       " |      0       |        1        |  118  |\n",
       " |      0       |        0        |  618  |\n",
       " +--------------+-----------------+-------+\n",
       " [16 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pixel_model.evaluate(image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is poor, getting only about 46% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Can we improve the model using deep features\n",
    "\n",
    "We only have 2005 data points, so it is not possible to train a deep neural network effectively with so little data.  Instead, we will use transfer learning: using deep features trained on the full ImageNet dataset, we will train a simple model on this small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Computing deep features for our images\n",
    "\n",
    "The two lines below allow us to compute deep features.  This computation takes a little while, so we have already computed them and saved the results as a column in the data you loaded. \n",
    "\n",
    "(Note that if you would like to compute such deep features and have a GPU on your machine, you should use the GPU enabled GraphLab Create, which will be significantly faster for this task.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deep_learning_model = graphlab.load_model('http://s3.amazonaws.com/GraphLab-Datasets/deeplearning/imagenet_model_iter45')\n",
    "#image_train['deep_features'] = deep_learning_model.extract_features(image_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the column deep_features already contains the pre-computed deep features for this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">deep_features</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_array</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.242871761322,<br>1.09545373917, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[73.0, 77.0, 58.0, 71.0,<br>68.0, 50.0, 77.0, 69.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">33</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cat</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.525087952614, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7.0, 5.0, 8.0, 7.0, 5.0,<br>8.0, 5.0, 4.0, 6.0, 7.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">36</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cat</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.566015958786, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[169.0, 122.0, 65.0,<br>131.0, 108.0, 75.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">70</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">dog</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.12979578972, 0.0, 0.0,<br>0.778194487095, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[154.0, 179.0, 152.0,<br>159.0, 183.0, 157.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">90</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.71786928177, 0.0, 0.0,<br>0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[216.0, 195.0, 180.0,<br>201.0, 178.0, 160.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">97</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">automobile</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.57818555832, 0.0, 0.0,<br>0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[33.0, 44.0, 27.0, 29.0,<br>44.0, 31.0, 32.0, 45.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">107</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">dog</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 0.0,<br>0.220677852631, 0.0,  ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[97.0, 51.0, 31.0, 104.0,<br>58.0, 38.0, 107.0, 61.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">121</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 0.23753464222, 0.0,<br>0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[93.0, 96.0, 88.0, 102.0,<br>106.0, 97.0, 117.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">automobile</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 0.0, 0.0, 0.0, 0.0,<br>0.0, 7.5737862587, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[35.0, 59.0, 53.0, 36.0,<br>56.0, 56.0, 42.0, 62.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.658935725689, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[205.0, 193.0, 195.0,<br>200.0, 187.0, 193.0, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tint\n",
       "\timage\tImage\n",
       "\tlabel\tstr\n",
       "\tdeep_features\tarray\n",
       "\timage_array\tarray\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-----+----------------------+------------+-------------------------------+\n",
       "|  id |        image         |   label    |         deep_features         |\n",
       "+-----+----------------------+------------+-------------------------------+\n",
       "|  24 | Height: 32 Width: 32 |    bird    | [0.242871761322, 1.0954537... |\n",
       "|  33 | Height: 32 Width: 32 |    cat     | [0.525087952614, 0.0, 0.0,... |\n",
       "|  36 | Height: 32 Width: 32 |    cat     | [0.566015958786, 0.0, 0.0,... |\n",
       "|  70 | Height: 32 Width: 32 |    dog     | [1.12979578972, 0.0, 0.0, ... |\n",
       "|  90 | Height: 32 Width: 32 |    bird    | [1.71786928177, 0.0, 0.0, ... |\n",
       "|  97 | Height: 32 Width: 32 | automobile | [1.57818555832, 0.0, 0.0, ... |\n",
       "| 107 | Height: 32 Width: 32 |    dog     | [0.0, 0.0, 0.220677852631,... |\n",
       "| 121 | Height: 32 Width: 32 |    bird    | [0.0, 0.23753464222, 0.0, ... |\n",
       "| 136 | Height: 32 Width: 32 | automobile | [0.0, 0.0, 0.0, 0.0, 0.0, ... |\n",
       "| 138 | Height: 32 Width: 32 |    bird    | [0.658935725689, 0.0, 0.0,... |\n",
       "+-----+----------------------+------------+-------------------------------+\n",
       "+-------------------------------+\n",
       "|          image_array          |\n",
       "+-------------------------------+\n",
       "| [73.0, 77.0, 58.0, 71.0, 6... |\n",
       "| [7.0, 5.0, 8.0, 7.0, 5.0, ... |\n",
       "| [169.0, 122.0, 65.0, 131.0... |\n",
       "| [154.0, 179.0, 152.0, 159.... |\n",
       "| [216.0, 195.0, 180.0, 201.... |\n",
       "| [33.0, 44.0, 27.0, 29.0, 4... |\n",
       "| [97.0, 51.0, 31.0, 104.0, ... |\n",
       "| [93.0, 96.0, 88.0, 102.0, ... |\n",
       "| [35.0, 59.0, 53.0, 36.0, 5... |\n",
       "| [205.0, 193.0, 195.0, 200.... |\n",
       "+-------------------------------+\n",
       "[10 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Given the deep features, let's train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: Detected extremely low variance for feature(s) 'deep_features' because all entries are nearly the same.\n",
       "Proceeding with model training using all features. If the model does not provide results of adequate quality, exclude the above mentioned feature(s) from the input dataset.</pre>"
      ],
      "text/plain": [
       "WARNING: Detected extremely low variance for feature(s) 'deep_features' because all entries are nearly the same.\n",
       "Proceeding with model training using all features. If the model does not provide results of adequate quality, exclude the above mentioned feature(s) from the input dataset."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 1909</pre>"
      ],
      "text/plain": [
       "Number of examples          : 1909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 4</pre>"
      ],
      "text/plain": [
       "Number of classes           : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 4096</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 4096"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 12291</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 12291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 5        | 0.000131  | 2.395780     | 0.738083          | 0.729167            |</pre>"
      ],
      "text/plain": [
       "| 1         | 5        | 0.000131  | 2.395780     | 0.738083          | 0.729167            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 9        | 0.250000  | 3.618075     | 0.761131          | 0.718750            |</pre>"
      ],
      "text/plain": [
       "| 2         | 9        | 0.250000  | 3.618075     | 0.761131          | 0.718750            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 10       | 0.250000  | 3.990951     | 0.764274          | 0.729167            |</pre>"
      ],
      "text/plain": [
       "| 3         | 10       | 0.250000  | 3.990951     | 0.764274          | 0.729167            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 11       | 0.250000  | 4.383733     | 0.772656          | 0.739583            |</pre>"
      ],
      "text/plain": [
       "| 4         | 11       | 0.250000  | 4.383733     | 0.772656          | 0.739583            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 12       | 0.250000  | 4.760767     | 0.781037          | 0.760417            |</pre>"
      ],
      "text/plain": [
       "| 5         | 12       | 0.250000  | 4.760767     | 0.781037          | 0.760417            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 13       | 0.250000  | 5.148381     | 0.791514          | 0.760417            |</pre>"
      ],
      "text/plain": [
       "| 6         | 13       | 0.250000  | 5.148381     | 0.791514          | 0.760417            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 17       | 0.250000  | 6.651318     | 0.867994          | 0.729167            |</pre>"
      ],
      "text/plain": [
       "| 10        | 17       | 0.250000  | 6.651318     | 0.867994          | 0.729167            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deep_features_model = graphlab.logistic_classifier.create(image_train,\n",
    "                                                         features=['deep_features'],\n",
    "                                                         target='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apply the deep features model to first few images of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "image_test[0:3]['image'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['cat', 'automobile', 'cat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_features_model.predict(image_test[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier with deep features gets all of these images right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compute test_data accuracy of deep_features_model\n",
    "\n",
    "As we can see, deep features provide us with significantly better accuracy (about 78%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.788, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 16\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        2        |   12  |\n",
       " |      2       |        0        |   39  |\n",
       " |      1       |        2        |  115  |\n",
       " |      3       |        3        |  735  |\n",
       " |      1       |        3        |   66  |\n",
       " |      3       |        2        |  206  |\n",
       " |      0       |        3        |   7   |\n",
       " |      2       |        1        |   66  |\n",
       " |      0       |        1        |   20  |\n",
       " |      0       |        0        |  961  |\n",
       " +--------------+-----------------+-------+\n",
       " [16 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_features_model.evaluate(image_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
